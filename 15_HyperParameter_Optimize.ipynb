{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 하이퍼파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV,train_test_split\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import recall_score, accuracy_score,f1_score,roc_auc_score,confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_split_data(X, y):\n",
    "    \"\"\"\n",
    "    전처리와 데이터 분할을 수행하는 함수입니다.\n",
    "    \"\"\"\n",
    "    X = pd.get_dummies(X)\n",
    "    X = X.rename(columns = lambda x:x.replace(',', ' '))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, stratify=y_train)\n",
    "\n",
    "    print(f\"훈련 데이터셋의 입력 데이터의 크기: {X_train.shape}, 타겟값의 크기: {y_train.shape}\")\n",
    "    print(f\"테스트 데이터셋의 입력 데이터의 크기: {X_test.shape}, 타겟값의 크기: {y_test.shape}\")\n",
    "    print(f\"검증 데이터셋의 입력 데이터의 크기: {X_val.shape}, 타겟값의 크기: {y_val.shape}\")\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_fit(X_train, y_train, X_test, y_test, X_val, y_val):\n",
    "    \"\"\"\n",
    "    그리드서치로 하이퍼파라미터를 찾는 함수입니다.\n",
    "    -------------------------------------------------------\n",
    "    input = X_train, y_train, X_test, y_test, X_val, y_val\n",
    "    return = 예측성능(dict), 파리미터(dict), 그리드서치 모델(object)\n",
    "    -------------------------------------------------------\n",
    "    \"\"\"\n",
    "    # 하이퍼파라미터 검색 후 예측 성능을 담는 딕셔너리\n",
    "    results_dict = {}\n",
    "\n",
    "    # xbg모델 객체 생성\n",
    "    xgbc0 = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                            booster='gbtree',\n",
    "                            eval_metric='auc',\n",
    "                            tree_method='hist',\n",
    "                            grow_policy='lossguide',\n",
    "                            use_label_encoder=False)\n",
    "    xgbc0.fit(X_train , y_train)\n",
    "\n",
    "    # 기본 파라미터 추출\n",
    "    default_params = {}\n",
    "    gparams = xgbc0.get_params()\n",
    "\n",
    "    # 기본 파리미터 리스트로 묶기\n",
    "    for key in gparams.keys():\n",
    "        gp = gparams[key]\n",
    "        default_params[key] = [gp]\n",
    "\n",
    "    # 그리드서치 및 교차검증\n",
    "    clf0 = GridSearchCV(estimator=xgbc0, scoring='accuracy', param_grid=default_params, return_train_score=True, verbose=0, cv=3)\n",
    "    clf0.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    # 결과 데이터프레임으로 변환\n",
    "    df = pd.DataFrame(clf0.cv_results_)\n",
    "\n",
    "    # 혼동행렬\n",
    "    train_predictions = clf0.predict(X_train)\n",
    "    test_predictions = clf0.predict(X_test)\n",
    "    unseen_predictions = clf0.predict(X_val)\n",
    "    unseen_predictions_proba = clf0.predict_proba(X_val)[:, 1]\n",
    "    unseen_predictions_threds = unseen_predictions_proba >= 0.4\n",
    "\n",
    "    # 혼동행렬\n",
    "    cfm_train = confusion_matrix(y_train, train_predictions)\n",
    "    cfm_test = confusion_matrix(y_test, test_predictions)\n",
    "    cfm_unseen = confusion_matrix(y_val, unseen_predictions)\n",
    "    cfm_unseen_threds = confusion_matrix(y_val, unseen_predictions_threds)\n",
    "    \n",
    "    # 재현율\n",
    "    accs_train = recall_score(y_train, train_predictions)\n",
    "    accs_test = recall_score(y_test, test_predictions)\n",
    "    accs_unseen = recall_score(y_val, unseen_predictions)\n",
    "    accs_unseen_threds = recall_score(y_val, unseen_predictions_threds)\n",
    "    \n",
    "    # F1-Score\n",
    "    f1s_train_p1 = f1_score(y_train, train_predictions, pos_label=1)\n",
    "    f1s_train_p0 = f1_score(y_train, train_predictions, pos_label=0)\n",
    "    f1s_test_p1 = f1_score(y_test, test_predictions, pos_label=1)\n",
    "    f1s_test_p0 = f1_score(y_test, test_predictions, pos_label=0)\n",
    "    f1s_unseen_p1 = f1_score(y_val, unseen_predictions, pos_label=1)\n",
    "    f1s_unseen_p0 = f1_score(y_val, unseen_predictions, pos_label=0)\n",
    "    f1s_unseen_threds_p1 = f1_score(y_val, unseen_predictions_threds, pos_label=1)\n",
    "    f1s_unseen_threds_p0 = f1_score(y_val, unseen_predictions_threds, pos_label=0)\n",
    "    \n",
    "    # ROC-Score\n",
    "    test_ras = roc_auc_score(y_test, clf0.predict_proba(X_test)[:,1])\n",
    "    unseen_ras = roc_auc_score(y_val, clf0.predict_proba(X_val)[:,1])\n",
    "    \n",
    "    # 최적의 파라미터 목록\n",
    "    bp = clf0.best_params_\n",
    "    \n",
    "    # 결과 저장\n",
    "    results_dict[f'xgbc0'] = {'iterable_parameter': np.nan,\n",
    "                                'classifier': deepcopy(clf0),\n",
    "                                'cv_results': df.copy(),\n",
    "                                'cfm_train': cfm_train,\n",
    "                                'cfm_test': cfm_test,\n",
    "                                'cfm_unseen': cfm_unseen,\n",
    "                                'cfm_unseen_threds': cfm_unseen_threds,\n",
    "                                'train_recall': accs_train,\n",
    "                                'test_recall': accs_test,\n",
    "                                'unseen_recall': accs_unseen,\n",
    "                                'unseen_threds_recall': accs_unseen_threds,\n",
    "                                'train F1-score label 1': f1s_train_p1,\n",
    "                                'train F1-score label 0': f1s_train_p0,\n",
    "                                'test F1-score label 1': f1s_test_p1,\n",
    "                                'test F1-score label 0': f1s_test_p0,\n",
    "                                'unseen F1-score label 1': f1s_unseen_p1,\n",
    "                                'unseen F1-score label 0': f1s_unseen_p0,\n",
    "                                'unseen threds F1-score label 1': f1s_unseen_threds_p1,\n",
    "                                'unseen threds F1-score label 0': f1s_unseen_threds_p0,\n",
    "                                'test roc auc score': test_ras,\n",
    "                                'unseen roc auc score': unseen_ras,\n",
    "                                'best_params': bp,\n",
    "                                'predict_proba':unseen_predictions_proba}\n",
    "    \n",
    "    return results_dict, default_params, clf0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinate_descent(X_train, y_train, X_test, y_test, X_val, y_val, param_grid, default_params, params, results_dict, clf0):\n",
    "    \"\"\"\n",
    "    그리드서치를 수행한 것과 coordinate descent 기법으로 찾은 최적의 하이퍼파라미터를 비교하는 함수입니다.\n",
    "    -----------------------------------------------------------------------------------------------\n",
    "    input = X_train, y_train, X_test, y_test, X_val, y_val, param_grid, default_params, params, results_dict, clf0\n",
    "    return = 예측성능(dict), 파라미터조합개수(int)\n",
    "    -----------------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    gcvj = np.cumsum([len(x) for x in param_grid.values()])[-1]\n",
    "\n",
    "    for i,grid_key in enumerate(param_grid.keys()):\n",
    "        for param_key in params.keys():\n",
    "            if param_key == grid_key:\n",
    "                params[param_key] = param_grid[grid_key]\n",
    "            else:\n",
    "                try:\n",
    "                    param_value = [clf.best_params_[param_key]]\n",
    "                    params[param_key] = param_value\n",
    "                except:\n",
    "                    param_value = [clf0.best_params_[param_key]]\n",
    "                    params[param_key] = param_value\n",
    "        \n",
    "        xgbc = xgb.XGBClassifier(**default_params)\n",
    "        \n",
    "        clf = GridSearchCV(estimator=xgbc, param_grid=params, scoring='accuracy', return_train_score=True, verbose=0, cv=3)\n",
    "        clf.fit(X_train, y_train.values.ravel())\n",
    "        \n",
    "        df = pd.DataFrame(clf.cv_results_)\n",
    "        \n",
    "        train_predictions = clf.predict(X_train)\n",
    "        test_predictions = clf.predict(X_test)\n",
    "        unseen_predictions = clf.predict(X_val)\n",
    "        unseen_predictions_proba = clf.predict_proba(X_val)[:, 1]\n",
    "        unseen_predictions_threds = unseen_predictions_proba >= 0.4\n",
    "\n",
    "        cfm_train = confusion_matrix(y_train, train_predictions)\n",
    "        cfm_test = confusion_matrix(y_test, test_predictions)\n",
    "        cfm_unseen = confusion_matrix(y_val, unseen_predictions)\n",
    "        cfm_unseen_threds = confusion_matrix(y_val, unseen_predictions_threds)\n",
    "        \n",
    "        accs_train = recall_score(y_train, train_predictions)\n",
    "        accs_test = recall_score(y_test, test_predictions)\n",
    "        accs_unseen = recall_score(y_val, unseen_predictions)\n",
    "        accs_unseen_threds = recall_score(y_val, unseen_predictions_threds)\n",
    "        \n",
    "        f1s_train_p1 = f1_score(y_train, train_predictions, pos_label=1)\n",
    "        f1s_train_p0 = f1_score(y_train, train_predictions, pos_label=0)\n",
    "        f1s_test_p1 = f1_score(y_test, test_predictions, pos_label=1)\n",
    "        f1s_test_p0 = f1_score(y_test, test_predictions, pos_label=0)\n",
    "        f1s_unseen_p1 = f1_score(y_val, unseen_predictions, pos_label=1)\n",
    "        f1s_unseen_p0 = f1_score(y_val, unseen_predictions, pos_label=0)\n",
    "        f1s_unseen_threds_p1 = f1_score(y_val, unseen_predictions_threds, pos_label=1)\n",
    "        f1s_unseen_threds_p0 = f1_score(y_val, unseen_predictions_threds, pos_label=0)\n",
    "\n",
    "        test_ras = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "        unseen_ras = roc_auc_score(y_val, clf.predict_proba(X_val)[:,1])\n",
    "    \n",
    "        bp = clf.best_params_\n",
    "        \n",
    "        results_dict[f'xgbc{i+1}'] = {'iterable_parameter': grid_key,\n",
    "                                    'classifier': deepcopy(clf),\n",
    "                                    'cv_results': df.copy(),\n",
    "                                    'cfm_train': cfm_train,\n",
    "                                    'cfm_test': cfm_test,\n",
    "                                    'cfm_unseen': cfm_unseen,\n",
    "                                    'cfm_unseen_threds': cfm_unseen_threds,\n",
    "                                    'train_recall': accs_train,\n",
    "                                    'test_recall': accs_test,\n",
    "                                    'unseen_recall': accs_unseen,\n",
    "                                    'unseen_threds_recall': accs_unseen_threds,\n",
    "                                    'train F1-score label 1': f1s_train_p1,\n",
    "                                    'train F1-score label 0': f1s_train_p0,\n",
    "                                    'test F1-score label 1': f1s_test_p1,\n",
    "                                    'test F1-score label 0': f1s_test_p0,\n",
    "                                    'unseen F1-score label 1': f1s_unseen_p1,\n",
    "                                    'unseen F1-score label 0': f1s_unseen_p0,\n",
    "                                    'unseen threds F1-score label 1': f1s_unseen_threds_p1,\n",
    "                                    'unseen threds F1-score label 0': f1s_unseen_threds_p0,\n",
    "                                    'test roc auc score': test_ras,\n",
    "                                    'unseen roc auc score': unseen_ras,\n",
    "                                    'best_params': bp,\n",
    "                                    'predict_proba':unseen_predictions_proba}\n",
    "                                    \n",
    "    return results_dict, gcvj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomsearch_fit(X_train, y_train, X_test, y_test, X_val, y_val, param_grid, default_params, results_dict, gcvj):\n",
    "    \"\"\"\n",
    "    랜덤서치를 통해  최적의 하이퍼파라미터를 찾는 함수입니다.\n",
    "    -----------------------------------------------------------------------------------------------\n",
    "    input = X_train, y_train, X_test, y_test, X_val, y_val, param_grid, default_params, results_dict, gcvj\n",
    "    return = 예측성능(dict)\n",
    "    -----------------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    rcvj = gcvj\n",
    "\n",
    "    default_params_xgb = {}\n",
    "\n",
    "    for key in default_params.keys():\n",
    "        default_params_xgb[key] = default_params[key][0]\n",
    "\n",
    "    xgbc = xgb.XGBClassifier(**default_params_xgb)\n",
    "\n",
    "    clf = RandomizedSearchCV(estimator=xgbc, param_distributions=param_grid, scoring='accuracy', return_train_score=True, verbose=0, cv=3, n_iter=rcvj)\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "        \n",
    "    df = pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "    train_predictions = clf.predict(X_train)\n",
    "    test_predictions = clf.predict(X_test)\n",
    "    unseen_predictions = clf.predict(X_val)\n",
    "    unseen_predictions_proba = clf.predict_proba(X_val)[:, 1]\n",
    "    unseen_predictions_threds = unseen_predictions_proba >= 0.4\n",
    "\n",
    "    cfm_train = confusion_matrix(y_train, train_predictions)\n",
    "    cfm_test = confusion_matrix(y_test, test_predictions)\n",
    "    cfm_unseen = confusion_matrix(y_val, unseen_predictions)\n",
    "    cfm_unseen_threds = confusion_matrix(y_val, unseen_predictions_threds)\n",
    "    \n",
    "    accs_train = recall_score(y_train, train_predictions)\n",
    "    accs_test = recall_score(y_test, test_predictions)\n",
    "    accs_unseen = recall_score(y_val, unseen_predictions)\n",
    "    accs_unseen_threds = recall_score(y_val, unseen_predictions_threds)\n",
    "    \n",
    "    f1s_train_p1 = f1_score(y_train, train_predictions, pos_label=1)\n",
    "    f1s_train_p0 = f1_score(y_train, train_predictions, pos_label=0)\n",
    "    f1s_test_p1 = f1_score(y_test, test_predictions, pos_label=1)\n",
    "    f1s_test_p0 = f1_score(y_test, test_predictions, pos_label=0)\n",
    "    f1s_unseen_p1 = f1_score(y_val, unseen_predictions, pos_label=1)\n",
    "    f1s_unseen_p0 = f1_score(y_val, unseen_predictions, pos_label=0)\n",
    "    f1s_unseen_threds_p1 = f1_score(y_val, unseen_predictions_threds, pos_label=1)\n",
    "    f1s_unseen_threds_p0 = f1_score(y_val, unseen_predictions_threds, pos_label=0)\n",
    "    \n",
    "    test_ras = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    unseen_ras = roc_auc_score(y_val, clf.predict_proba(X_val)[:,1])\n",
    "    \n",
    "    bp = clf.best_params_\n",
    "    \n",
    "    results_dict['xgbc_rcv'] = {'classifier': deepcopy(clf),\n",
    "                                'cv_results': df.copy(),\n",
    "                                'cfm_train': cfm_train,\n",
    "                                'cfm_test': cfm_test,\n",
    "                                'cfm_unseen': cfm_unseen,\n",
    "                                'cfm_unseen_threds': cfm_unseen_threds,\n",
    "                                'train_recall': accs_train,\n",
    "                                'test_recall': accs_test,\n",
    "                                'unseen_recall': accs_unseen,\n",
    "                                'unseen_threds_recall': accs_unseen_threds,\n",
    "                                'train F1-score label 1': f1s_train_p1,\n",
    "                                'train F1-score label 0': f1s_train_p0,\n",
    "                                'test F1-score label 1': f1s_test_p1,\n",
    "                                'test F1-score label 0': f1s_test_p0,\n",
    "                                'unseen F1-score label 1': f1s_unseen_p1,\n",
    "                                'unseen F1-score label 0': f1s_unseen_p0,\n",
    "                                'unseen threds F1-score label 1': f1s_unseen_threds_p1,\n",
    "                                'unseen threds F1-score label 0': f1s_unseen_threds_p0,\n",
    "                                'test roc auc score': test_ras,\n",
    "                                'unseen roc auc score': unseen_ras,\n",
    "                                'best_params': bp,\n",
    "                                'predict_proba':unseen_predictions_proba}\n",
    "                                \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baysiansearch_fit(X_train, y_train, X_test, y_test, X_val, y_val, param_grid, default_params, results_dict, gcvj):\n",
    "    \"\"\"\n",
    "    베이지안서치를 통해  최적의 하이퍼파라미터를 찾는 함수입니다.\n",
    "    -----------------------------------------------------------------------------------------------\n",
    "    input = X_train, y_train, X_test, y_test, X_val, y_val, param_grid, default_params, results_dict, gcvj\n",
    "    return = 예측성능(dict)\n",
    "    -----------------------------------------------------------------------------------------------\n",
    "    \"\"\"\n",
    "    bcvj = int(gcvj)\n",
    "\n",
    "    default_params_xgb = {}\n",
    "\n",
    "    for key in default_params.keys():\n",
    "        default_params_xgb[key] = default_params[key][0]\n",
    "\n",
    "    xgbc = xgb.XGBClassifier(**default_params_xgb)\n",
    "\n",
    "    clf = BayesSearchCV(estimator=xgbc, search_spaces=param_grid, n_iter=bcvj, scoring='accuracy', cv=3, return_train_score=True, verbose=0)\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    df = pd.DataFrame(clf.cv_results_)\n",
    "\n",
    "    train_predictions = clf.predict(X_train)\n",
    "    test_predictions = clf.predict(X_test)\n",
    "    unseen_predictions = clf.predict(X_val)\n",
    "    unseen_predictions_proba = clf.predict_proba(X_val)[:, 1]\n",
    "    unseen_predictions_threds = unseen_predictions_proba >= 0.4\n",
    "\n",
    "    cfm_train = confusion_matrix(y_train, train_predictions)\n",
    "    cfm_test = confusion_matrix(y_test, test_predictions)\n",
    "    cfm_unseen = confusion_matrix(y_val, unseen_predictions)\n",
    "    cfm_unseen_threds = confusion_matrix(y_val, unseen_predictions_threds)\n",
    "    \n",
    "    accs_train = recall_score(y_train, train_predictions)\n",
    "    accs_test = recall_score(y_test, test_predictions)\n",
    "    accs_unseen = recall_score(y_val, unseen_predictions)\n",
    "    accs_unseen_threds = recall_score(y_val, unseen_predictions_threds)\n",
    "    \n",
    "    f1s_train_p1 = f1_score(y_train, train_predictions, pos_label=1)\n",
    "    f1s_train_p0 = f1_score(y_train, train_predictions, pos_label=0)\n",
    "    f1s_test_p1 = f1_score(y_test, test_predictions, pos_label=1)\n",
    "    f1s_test_p0 = f1_score(y_test, test_predictions, pos_label=0)\n",
    "    f1s_unseen_p1 = f1_score(y_val, unseen_predictions, pos_label=1)\n",
    "    f1s_unseen_p0 = f1_score(y_val, unseen_predictions, pos_label=0)\n",
    "    f1s_unseen_threds_p1 = f1_score(y_val, unseen_predictions_threds, pos_label=1)\n",
    "    f1s_unseen_threds_p0 = f1_score(y_val, unseen_predictions_threds, pos_label=0)\n",
    "    \n",
    "    test_ras = roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    unseen_ras = roc_auc_score(y_val, clf.predict_proba(X_val)[:,1])\n",
    "    \n",
    "    bp = clf.best_params_\n",
    "    \n",
    "    results_dict['xgbc_bcv'] = {'classifier': deepcopy(clf),\n",
    "                                'cv_results': df.copy(),\n",
    "                                'cfm_train': cfm_train,\n",
    "                                'cfm_test': cfm_test,\n",
    "                                'cfm_unseen': cfm_unseen,\n",
    "                                'cfm_unseen_threds': cfm_unseen_threds,\n",
    "                                'train_recall': accs_train,\n",
    "                                'test_recall': accs_test,\n",
    "                                'unseen_recall': accs_unseen,\n",
    "                                'unseen_threds_recall': accs_unseen_threds,\n",
    "                                'train F1-score label 1': f1s_train_p1,\n",
    "                                'train F1-score label 0': f1s_train_p0,\n",
    "                                'test F1-score label 1': f1s_test_p1,\n",
    "                                'test F1-score label 0': f1s_test_p0,\n",
    "                                'unseen F1-score label 1': f1s_unseen_p1,\n",
    "                                'unseen F1-score label 0': f1s_unseen_p0,\n",
    "                                'unseen threds F1-score label 1': f1s_unseen_threds_p1,\n",
    "                                'unseen threds F1-score label 0': f1s_unseen_threds_p0,\n",
    "                                'test roc auc score': test_ras,\n",
    "                                'unseen roc auc score': unseen_ras,\n",
    "                                'best_params': bp,\n",
    "                                'predict_proba':unseen_predictions_proba}\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(results_dict):\n",
    "    print(\"임계값 0.5 일 때, 예측 성능\")\n",
    "    for model in results_dict.keys():\n",
    "        print(f\"{model} - 재현율: {results_dict[model]['unseen_recall']}, F1-Score: {results_dict[model]['unseen F1-score label 1']}\")\n",
    "\n",
    "    print(\"임계값 0.4 일 때, 예측 성능\")\n",
    "    for model in results_dict.keys():\n",
    "        print(f\"{model} - 재현율: {results_dict[model]['unseen_threds_recall']}, F1-Score: {results_dict[model]['unseen threds F1-score label 1']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조합 1. 통계검정 재무/비재무, 통계검정 재무비율/파생재무비율, 재무등급, 지방지표, 재무비율점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋의 입력 데이터의 크기: (52527, 131), 타겟값의 크기: (52527,)\n",
      "테스트 데이터셋의 입력 데이터의 크기: (14592, 131), 타겟값의 크기: (14592,)\n",
      "검증 데이터셋의 입력 데이터의 크기: (5837, 131), 타겟값의 크기: (5837,)\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.read_csv('./custom_data/gridsearch_data_1.csv', encoding='cp949')\n",
    "\n",
    "X = df_1.drop(['휴폐업구분'], axis=1)\n",
    "y = df_1['휴폐업구분']\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = preprocess_and_split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating deepcopy of default parameters before manipulations\n",
    "results_dict_base, default_params, gridsearch_estimator = baseline_fit(X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "params = deepcopy(default_params)\n",
    "\n",
    "#setting grid of selected parameters for iteration\n",
    "param_grid = {'gamma': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4, 200],\n",
    "              'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.300000012, 0.4, 0.5, 0.6, 0.7],\n",
    "              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
    "              'n_estimators': [50,65,80,100,115,130,150],\n",
    "              'reg_alpha': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
    "              'reg_lambda': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200]}\n",
    "\n",
    "results_dict_coord, gcvj = coordinate_descent(X_train, y_train, X_test, y_test, X_val, y_val, param_grid, \n",
    "                                                default_params, params, results_dict_base, gridsearch_estimator)\n",
    "results_dict_random = randomsearch_fit(X_train, y_train, X_test, y_test, X_val, y_val, param_grid, \n",
    "                                                default_params, results_dict_coord, gcvj)\n",
    "results_dict_final = baysiansearch_fit(X_train, y_train, X_test, y_test, X_val, y_val, param_grid, \n",
    "                                                default_params, results_dict_random, gcvj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임계값 0.5 일 때, 예측 성능\n",
      "xgbc0 - 재현율: 0.6411960132890365, F1-Score: 0.7408829174664107\n",
      "xgbc1 - 재현율: 0.6445182724252492, F1-Score: 0.7475915221579961\n",
      "xgbc2 - 재현율: 0.6212624584717608, F1-Score: 0.7333333333333333\n",
      "xgbc3 - 재현율: 0.6212624584717608, F1-Score: 0.7347740667976425\n",
      "xgbc4 - 재현율: 0.6146179401993356, F1-Score: 0.7312252964426877\n",
      "xgbc5 - 재현율: 0.6146179401993356, F1-Score: 0.7312252964426877\n",
      "xgbc6 - 재현율: 0.6146179401993356, F1-Score: 0.7283464566929133\n",
      "xgbc_rcv - 재현율: 0.627906976744186, F1-Score: 0.7382812500000001\n",
      "xgbc_bcv - 재현율: 0.6112956810631229, F1-Score: 0.731610337972167\n",
      "임계값 0.4 일 때, 예측 성능\n",
      "xgbc0 - 재현율: 0.6777408637873754, F1-Score: 0.7597765363128492\n",
      "xgbc1 - 재현율: 0.6644518272425249, F1-Score: 0.7352941176470589\n",
      "xgbc2 - 재현율: 0.6511627906976745, F1-Score: 0.7340823970037454\n",
      "xgbc3 - 재현율: 0.6445182724252492, F1-Score: 0.7376425855513308\n",
      "xgbc4 - 재현율: 0.6345514950166113, F1-Score: 0.731800766283525\n",
      "xgbc5 - 재현율: 0.6345514950166113, F1-Score: 0.731800766283525\n",
      "xgbc6 - 재현율: 0.6345514950166113, F1-Score: 0.7346153846153847\n",
      "xgbc_rcv - 재현율: 0.6578073089700996, F1-Score: 0.7485822306238187\n",
      "xgbc_bcv - 재현율: 0.6511627906976745, F1-Score: 0.7452471482889733\n"
     ]
    }
   ],
   "source": [
    "eval(results_dict_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조합 2. 통계검정 재무/비재무, 통계검정 재무비율, 재무등급, 지방지표, 재무점수, 비재무점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋의 입력 데이터의 크기: (52527, 126), 타겟값의 크기: (52527,)\n",
      "테스트 데이터셋의 입력 데이터의 크기: (14592, 126), 타겟값의 크기: (14592,)\n",
      "검증 데이터셋의 입력 데이터의 크기: (5837, 126), 타겟값의 크기: (5837,)\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.read_csv('./custom_data/gridsearch_data_2.csv', encoding='cp949')\n",
    "\n",
    "X = df_1.drop(['휴폐업구분'], axis=1)\n",
    "y = df_1['휴폐업구분']\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = preprocess_and_split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating deepcopy of default parameters before manipulations\n",
    "results_dict_base, default_params, gridsearch_estimator = baseline_fit(X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "params = deepcopy(default_params)\n",
    "\n",
    "#setting grid of selected parameters for iteration\n",
    "param_grid = {'gamma': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4, 200],\n",
    "              'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.300000012, 0.4, 0.5, 0.6, 0.7],\n",
    "              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
    "              'n_estimators': [50,65,80,100,115,130,150],\n",
    "              'reg_alpha': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
    "              'reg_lambda': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200]}\n",
    "\n",
    "results_dict_coord, gcvj = coordinate_descent(X_train, y_train, X_test, y_test, X_val, y_val, param_grid, \n",
    "                                                default_params, params, results_dict_base, gridsearch_estimator)\n",
    "results_dict_random = randomsearch_fit(X_train, y_train, X_test, y_test, X_val, y_val, param_grid, \n",
    "                                                default_params, results_dict_coord, gcvj)\n",
    "results_dict_final = baysiansearch_fit(X_train, y_train, X_test, y_test, X_val, y_val, param_grid, \n",
    "                                                default_params, results_dict_random, gcvj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임계값 0.5 일 때, 예측 성능\n",
      "xgbc0 - 재현율: 0.6245847176079734, F1-Score: 0.7372549019607844\n",
      "xgbc1 - 재현율: 0.6146179401993356, F1-Score: 0.7212475633528265\n",
      "xgbc2 - 재현율: 0.6146179401993356, F1-Score: 0.7212475633528265\n",
      "xgbc3 - 재현율: 0.6112956810631229, F1-Score: 0.71875\n",
      "xgbc4 - 재현율: 0.6112956810631229, F1-Score: 0.71875\n",
      "xgbc5 - 재현율: 0.6312292358803987, F1-Score: 0.7392996108949418\n",
      "xgbc6 - 재현율: 0.6179401993355482, F1-Score: 0.7265625\n",
      "xgbc_rcv - 재현율: 0.6245847176079734, F1-Score: 0.7387033398821219\n",
      "xgbc_bcv - 재현율: 0.6378737541528239, F1-Score: 0.7500000000000001\n",
      "임계값 0.4 일 때, 예측 성능\n",
      "xgbc0 - 재현율: 0.6378737541528239, F1-Score: 0.7218045112781954\n",
      "xgbc1 - 재현율: 0.6511627906976745, F1-Score: 0.7354596622889306\n",
      "xgbc2 - 재현율: 0.6511627906976745, F1-Score: 0.7354596622889306\n",
      "xgbc3 - 재현율: 0.6411960132890365, F1-Score: 0.7352380952380954\n",
      "xgbc4 - 재현율: 0.6411960132890365, F1-Score: 0.7352380952380954\n",
      "xgbc5 - 재현율: 0.6411960132890365, F1-Score: 0.7380497131931165\n",
      "xgbc6 - 재현율: 0.6611295681063123, F1-Score: 0.7397769516728625\n",
      "xgbc_rcv - 재현율: 0.6744186046511628, F1-Score: 0.7588785046728973\n",
      "xgbc_bcv - 재현율: 0.654485049833887, F1-Score: 0.747628083491461\n"
     ]
    }
   ],
   "source": [
    "eval(results_dict_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조합 3. 통계검정 재무/비재무, 통계검정 재무비율, 재무등급"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋의 입력 데이터의 크기: (52536, 110), 타겟값의 크기: (52536,)\n",
      "테스트 데이터셋의 입력 데이터의 크기: (14594, 110), 타겟값의 크기: (14594,)\n",
      "검증 데이터셋의 입력 데이터의 크기: (5838, 110), 타겟값의 크기: (5838,)\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.read_csv('./custom_data/gridsearch_data_3.csv')\n",
    "\n",
    "X = df_1.drop(['휴폐업구분'], axis=1)\n",
    "y = df_1['휴폐업구분']\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = preprocess_and_split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating deepcopy of default parameters before manipulations\n",
    "results_dict_base, default_params, gridsearch_estimator = baseline_fit(X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "params = deepcopy(default_params)\n",
    "\n",
    "#setting grid of selected parameters for iteration\n",
    "param_grid = {'gamma': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4, 200],\n",
    "              'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.300000012, 0.4, 0.5, 0.6, 0.7],\n",
    "              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
    "              'n_estimators': [50,65,80,100,115,130,150],\n",
    "              'reg_alpha': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
    "              'reg_lambda': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200]}\n",
    "\n",
    "results_dict_coord, gcvj = coordinate_descent(X_train, y_train, X_test, y_test, X_val, y_val, param_grid, \n",
    "                                                default_params, params, results_dict_base, gridsearch_estimator)\n",
    "results_dict_random = randomsearch_fit(X_train, y_train, X_test, y_test, X_val, y_val, param_grid, \n",
    "                                                default_params, results_dict_coord, gcvj)\n",
    "results_dict_final = baysiansearch_fit(X_train, y_train, X_test, y_test, X_val, y_val, param_grid, \n",
    "                                                default_params, results_dict_random, gcvj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임계값 0.5 일 때, 예측 성능\n",
      "xgbc0 - 재현율: 0.5860927152317881, F1-Score: 0.6954813359528488\n",
      "xgbc1 - 재현율: 0.5960264900662252, F1-Score: 0.7086614173228347\n",
      "xgbc2 - 재현율: 0.5960264900662252, F1-Score: 0.7086614173228347\n",
      "xgbc3 - 재현율: 0.5761589403973509, F1-Score: 0.6918489065606361\n",
      "xgbc4 - 재현율: 0.5761589403973509, F1-Score: 0.6918489065606361\n",
      "xgbc5 - 재현율: 0.5761589403973509, F1-Score: 0.6918489065606361\n",
      "xgbc6 - 재현율: 0.5993377483443708, F1-Score: 0.7125984251968503\n",
      "xgbc_rcv - 재현율: 0.5927152317880795, F1-Score: 0.7075098814229249\n",
      "xgbc_bcv - 재현율: 0.5728476821192053, F1-Score: 0.6824457593688363\n",
      "임계값 0.4 일 때, 예측 성능\n",
      "xgbc0 - 재현율: 0.6192052980132451, F1-Score: 0.7069943289224951\n",
      "xgbc1 - 재현율: 0.6423841059602649, F1-Score: 0.7334593572778828\n",
      "xgbc2 - 재현율: 0.6423841059602649, F1-Score: 0.7334593572778828\n",
      "xgbc3 - 재현율: 0.6158940397350994, F1-Score: 0.711281070745698\n",
      "xgbc4 - 재현율: 0.6158940397350994, F1-Score: 0.711281070745698\n",
      "xgbc5 - 재현율: 0.6158940397350994, F1-Score: 0.711281070745698\n",
      "xgbc6 - 재현율: 0.6324503311258278, F1-Score: 0.722117202268431\n",
      "xgbc_rcv - 재현율: 0.6258278145695364, F1-Score: 0.7159090909090908\n",
      "xgbc_bcv - 재현율: 0.6059602649006622, F1-Score: 0.6971428571428572\n"
     ]
    }
   ],
   "source": [
    "eval(results_dict_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 베이스라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터셋의 입력 데이터의 크기: (52536, 55), 타겟값의 크기: (52536,)\n",
      "테스트 데이터셋의 입력 데이터의 크기: (14594, 55), 타겟값의 크기: (14594,)\n",
      "검증 데이터셋의 입력 데이터의 크기: (5838, 55), 타겟값의 크기: (5838,)\n"
     ]
    }
   ],
   "source": [
    "df_1 = pd.read_csv('./custom_data/baseline_data.csv', encoding='cp949')\n",
    "\n",
    "X = df_1.drop(['휴폐업구분'], axis=1)\n",
    "y = df_1['휴폐업구분']\n",
    "\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = preprocess_and_split_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating deepcopy of default parameters before manipulations\n",
    "results_dict_base, default_params, gridsearch_estimator = baseline_fit(X_train, y_train, X_test, y_test, X_val, y_val)\n",
    "params = deepcopy(default_params)\n",
    "\n",
    "#setting grid of selected parameters for iteration\n",
    "param_grid = {'gamma': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4, 200],\n",
    "              'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.300000012, 0.4, 0.5, 0.6, 0.7],\n",
    "              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
    "              'n_estimators': [50,65,80,100,115,130,150],\n",
    "              'reg_alpha': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
    "              'reg_lambda': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200]}\n",
    "\n",
    "results_dict_coord, gcvj = coordinate_descent(X_train, y_train, X_test, y_test, X_val, y_val, param_grid, \n",
    "                                                default_params, params, results_dict_base, gridsearch_estimator)\n",
    "results_dict_random = randomsearch_fit(X_train, y_train, X_test, y_test, X_val, y_val, param_grid, \n",
    "                                                default_params, results_dict_coord, gcvj)\n",
    "results_dict_final = baysiansearch_fit(X_train, y_train, X_test, y_test, X_val, y_val, param_grid, \n",
    "                                                default_params, results_dict_random, gcvj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임계값 0.5 일 때, 예측 성능\n",
      "xgbc0 - 재현율: 0.6125827814569537, F1-Score: 0.7156673114119921\n",
      "xgbc1 - 재현율: 0.6026490066225165, F1-Score: 0.7123287671232875\n",
      "xgbc2 - 재현율: 0.609271523178808, F1-Score: 0.7159533073929961\n",
      "xgbc3 - 재현율: 0.609271523178808, F1-Score: 0.7159533073929961\n",
      "xgbc4 - 재현율: 0.6125827814569537, F1-Score: 0.7184466019417476\n",
      "xgbc5 - 재현율: 0.6125827814569537, F1-Score: 0.7184466019417476\n",
      "xgbc6 - 재현율: 0.6026490066225165, F1-Score: 0.7109374999999999\n",
      "xgbc_rcv - 재현율: 0.609271523178808, F1-Score: 0.7215686274509804\n",
      "xgbc_bcv - 재현율: 0.6059602649006622, F1-Score: 0.7190569744597249\n",
      "임계값 0.4 일 때, 예측 성능\n",
      "xgbc0 - 재현율: 0.6357615894039735, F1-Score: 0.7218045112781956\n",
      "xgbc1 - 재현율: 0.6324503311258278, F1-Score: 0.7193973634651599\n",
      "xgbc2 - 재현율: 0.6390728476821192, F1-Score: 0.7269303201506591\n",
      "xgbc3 - 재현율: 0.6390728476821192, F1-Score: 0.7269303201506591\n",
      "xgbc4 - 재현율: 0.6423841059602649, F1-Score: 0.7265917602996254\n",
      "xgbc5 - 재현율: 0.6423841059602649, F1-Score: 0.7265917602996254\n",
      "xgbc6 - 재현율: 0.6324503311258278, F1-Score: 0.7234848484848484\n",
      "xgbc_rcv - 재현율: 0.6456953642384106, F1-Score: 0.7269303201506591\n",
      "xgbc_bcv - 재현율: 0.6357615894039735, F1-Score: 0.7229303201683592\n"
     ]
    }
   ],
   "source": [
    "eval(results_dict_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cabta')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a063b7be1b1d22be0fca1b26cf478769b2ebdd8896aff1eef11b858cbacfa39b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
